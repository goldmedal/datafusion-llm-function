use crate::llm::functions::AsyncScalarUDF;
use datafusion::arrow::array::{make_array, Array, ArrayRef, MutableArrayData, RecordBatch};
use datafusion::arrow::datatypes::{Field, Schema, SchemaRef};
use datafusion::common::{internal_err, not_impl_err, Result};
use datafusion::config::ConfigOptions;
use datafusion::logical_expr::{ColumnarValue, ScalarUDF};
use datafusion::physical_expr::{PhysicalExpr, ScalarFunctionExpr};
use std::fmt::Display;
use std::sync::Arc;

/// Wrapper for a Async function that can be used in a DataFusion query
#[derive(Debug, Clone)]
pub struct AsyncFuncExpr {
    /// The name of the output column this function will generate
    pub name: String,
    /// The actual function (always `ScalarFunctionExpr`)
    pub func: Arc<dyn PhysicalExpr>,
}

impl Display for AsyncFuncExpr {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        write!(f, "async_expr(name={}, expr={})", self.name, self.func)
    }
}

impl AsyncFuncExpr {
    /// create a new AsyncFuncExpr
    pub fn new(name: impl Into<String>, func: Arc<dyn PhysicalExpr>) -> Self {
        Self {
            name: name.into(),
            func,
        }
    }

    /// return if this is an async function
    pub fn is_async_func(func: &ScalarUDF) -> bool {
        func.inner()
            .as_any()
            .downcast_ref::<AsyncScalarUDF>()
            .is_some()
    }

    /// return the name of the output column
    pub fn name(&self) -> &str {
        &self.name
    }

    /// Return the output field generated by evaluating this function
    pub fn field(&self, input_schema: &Schema) -> Field {
        Field::new(
            &self.name,
            self.func.data_type(input_schema).unwrap(),
            self.func.nullable(input_schema).unwrap(),
        )
    }

    /// Return the ideal batch size for this function
    pub fn ideal_batch_size(&self) -> Result<Option<usize>> {
        if let Some(expr) = self.func.as_any().downcast_ref::<ScalarFunctionExpr>() {
            if let Some(udf) = expr.fun().inner().as_any().downcast_ref::<AsyncScalarUDF>() {
                return Ok(udf.ideal_batch_size());
            }
        }
        not_impl_err!("Can't get ideal_batch_size from {:?}", self.func)
    }

    /// This (async) function is called for each record batch to evaluate the LLM expressions
    ///
    /// The output is the output of evaluating the llm expression and the input record batch
    pub async fn invoke_batch(&self, batch: &RecordBatch) -> Result<ArrayRef> {
        let Some(llm_function) = self.func.as_any().downcast_ref::<ScalarFunctionExpr>() else {
            return internal_err!(
                "unexpected function type, expected ScalarFunctionExpr, got: {:?}",
                self.func
            );
        };
        let Some(async_udf) = llm_function
            .fun()
            .inner()
            .as_any()
            .downcast_ref::<AsyncScalarUDF>()
        else {
            return not_impl_err!(
                "Don't know how to evaluate async function: {:?}",
                llm_function
            );
        };

        async_udf.invoke_async(batch).await
    }

    pub async fn invoke_with_args(
        &self,
        batch: &RecordBatch,
        option: &ConfigOptions,
    ) -> Result<ColumnarValue> {
        let Some(llm_function) = self.func.as_any().downcast_ref::<ScalarFunctionExpr>() else {
            return internal_err!(
                "unexpected function type, expected ScalarFunctionExpr, got: {:?}",
                self.func
            );
        };

        let Some(async_udf) = llm_function
            .fun()
            .inner()
            .as_any()
            .downcast_ref::<AsyncScalarUDF>()
        else {
            return not_impl_err!(
                "Don't know how to evaluate async function: {:?}",
                llm_function
            );
        };

        let mut result_batches = vec![];
        if let Some(ideal_batch_size) = self.ideal_batch_size()? {
            let mut remainder = batch.clone();
            while remainder.num_rows() > 0 {
                let size = if ideal_batch_size > remainder.num_rows() {
                    remainder.num_rows()
                } else {
                    ideal_batch_size
                };

                let current_batch = remainder.slice(0, size); // get next 10 rows
                remainder =
                    remainder.slice(size, remainder.num_rows() - size);
                let args = llm_function
                    .args()
                    .iter()
                    .map(|e| e.evaluate(&current_batch))
                    .collect::<Result<Vec<_>>>()?;
                result_batches.push(
                    async_udf
                        .invoke_async_with_args(
                            AsyncScalarFunctionArgs {
                                args: args.to_vec(),
                                number_rows: current_batch.num_rows(),
                                schema: current_batch.schema(),
                            },
                            option,
                        )
                        .await?,
                );
            }
        } else {
            let args = llm_function
                .args()
                .iter()
                .map(|e| e.evaluate(batch))
                .collect::<Result<Vec<_>>>()?;

            result_batches.push(
                async_udf
                    .invoke_async_with_args(
                        AsyncScalarFunctionArgs {
                            args: args.to_vec(),
                            number_rows: batch.num_rows(),
                            schema: batch.schema(),
                        },
                        option,
                    )
                    .await?,
            );
        }

        let datas = result_batches
            .iter()
            .map(|b| b.to_data())
            .collect::<Vec<_>>();
        let total_len = datas.iter().map(|d| d.len()).sum();
        let mut mutable = MutableArrayData::new(datas.iter().collect(), false, total_len);
        datas.iter().enumerate().for_each(|(i, data)| {
            mutable.extend(i, 0, data.len());
        });
        let array_ref = make_array(mutable.freeze());
        Ok(ColumnarValue::Array(array_ref))
    }
}

impl PartialEq<Arc<dyn PhysicalExpr>> for AsyncFuncExpr {
    fn eq(&self, other: &Arc<dyn PhysicalExpr>) -> bool {
        &self.func == other
    }
}

#[derive(Debug)]
pub struct AsyncScalarFunctionArgs {
    pub args: Vec<ColumnarValue>,
    pub number_rows: usize,
    pub schema: SchemaRef,
}
